{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RayKim\uc758 \uae30\uc220 \ube14\ub85c\uadf8\uc785\ub2c8\ub2e4. \uac1c\ubc1c\ud558\ub294 Technical Writer\uc785\ub2c8\ub2e4. \uad00\uc2ec\ubd84\uc57c: Tech Writing, Document Engineering, AI, Blockchain","title":"RayKim\uc758 \uae30\uc220 \ube14\ub85c\uadf8\uc785\ub2c8\ub2e4."},{"location":"#raykim","text":"\uac1c\ubc1c\ud558\ub294 Technical Writer\uc785\ub2c8\ub2e4. \uad00\uc2ec\ubd84\uc57c: Tech Writing, Document Engineering, AI, Blockchain","title":"RayKim\uc758 \uae30\uc220 \ube14\ub85c\uadf8\uc785\ub2c8\ub2e4."},{"location":"output/","text":"Change History Commit: cdfbba1afd7a0c9e9d065ab292f2ddea3de7bb23 Author : raykim Date : 2024-01-13 10:55:58+09:00 Message : \uacbd\ub85c \uc778\uc2dd \ubb38\uc81c. \uc0c1\ub300 \uacbd\ub85c -> \uc808\ub300 \uacbd\ub85c Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" index 707fcfd..414a673 100644 --- \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" @@ -50,7 +50,7 @@ def check_hyperlinks_in_directory(directory): return report # Replace 'your_directory_path' with the path to the directory you want to check -directory_path = './input/dev4' +directory_path = 'C:/Users/khy/Documents/personal/workspace/toolbox/\ub9c1\ud06c \uccb4\ucee4/input/dev4/authv4' link_report = check_hyperlinks_in_directory(directory_path) # Print the report Commit: 728f4fa5ab8e981cd7db66bb2cf65db2bea386a1 Author : raykim Date : 2024-01-13 11:33:06+09:00 Message : \ub9c1\ud06c \uc8fc\uc18c \ub0b4\uc5d0 \uc6cc\ub4dc\ud504\ub808\uc2a4 custom variable\uc744 \uc0ac\uc6a9\ud558\ub294 \ub9c1\ud06c\uac00 \uc788\uc74c. \uc774\ub97c \ub2e4\uc2dc \uc815\uc0c1\uc801\uc778 URL \uc8fc\uc18c\ub85c \ubcc0\ud658\ud558\ub294 \uc791\uc5c5 \uad6c\ud604 Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" index 414a673..6ae435c 100644 --- \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" @@ -3,6 +3,12 @@ import requests from bs4 import BeautifulSoup from urllib.parse import urljoin +CV_DICT = {\"[cgv hive_sdk4_unity_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Unity3D\", + \"[cgv hive_sdk4_android_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Android\", + \"[cgv hive_sdk4_ios_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/iOS\", + \"[cgv hive_sdk4_cpp_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/CPP\", +} + def find_html_files(directory): \"\"\"Recursively find all HTML files in the given directory.\"\"\" html_files = [] @@ -12,12 +18,19 @@ def find_html_files(directory): html_files.append(os.path.join(root, file)) return html_files +def custom_variable_parser(link, replacements=CV_DICT): + for target, replacement in replacements.items(): + if target in link: + link = link.replace(target, replacement) + return link + def get_hyperlinks(html_file): \"\"\"Extract hyperlinks from an HTML file, excluding image links.\"\"\" with open(html_file, 'r', encoding='utf-8') as file: contents = file.read() soup = BeautifulSoup(contents, 'html.parser') links = [a['href'] for a in soup.find_all('a', href=True) if not a['href'].lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))] + links = [custom_variable_parser(link) for link in links] return links def check_link_status(url): Commit: c4a9daedabf54d07f5086d9be64c090b380dc652 Author : raykim Date : 2024-01-13 16:03:39+09:00 Message : \ub9c1\ud06c \uccb4\ud06c\ub97c, \uc6f9 \ub9c1\ud06c, \ub85c\uceec \ub9c1\ud06c (\ub85c\uceec \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc788\ub294 \ub2e4\ub978 \ud398\uc774\uc9c0\uc758 \ub2e4\ub978 \uc139\uc158\uc5d0 \uc788\ub294 \uc575\ucee4\ub85c \uc774\ub3d9), with-in page \ub85c\uceec \ub9c1\ud06c (\ud604\uc7ac \ud398\uc774\uc9c0\uc758 \ub124\uc784\ub4dc \uc575\ucee4\ub85c \uc774\ub3d9)\ub85c \ub098\ub204\uc5b4\uc11c \uc2e4\ud589. \uc804\ucc98\ub9ac \ud568\uc218\ub294 \uc6f9\uc5d0\uc11c \uc4f0\ub294 \uc0c1\ub300 \uacbd\ub85c\ub97c \ub85c\uceec \uae30\uc900\uc73c\ub85c \ub2e4\uc2dc \ubcc0\ub3d9(1\ub381\uc2a4\uc529 \uc81c\uac70)\ud558\ub294 \uc791\uc5c5 \uc218\ud589. \uc218\uc815\ud55c \uc0c1\ub300 \uacbd\ub85c \ucc98\ub9ac\ub97c \uc544\uc9c1 \ubcf4\uc644\ud574\uc57c \ud568. \ubd88 \ud544\uc694\ud55c \ub85c\uc9c1\uc774 \ub4e4\uc5b4\uac04 \uac83\uc73c\ub85c \ubcf4\uc784. \ub4a4\uc5d0 \"/\"\uac00 \ubd99\uc5c8\uc744 \ub54c \ucc98\ub9ac\uac00 \uacfc\uc5f0 \ud544\uc694\ud55c\uc9c0 \uccb4\ud06c\ud574\uc57c\ud568. Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" index 6ae435c..ea01d58 100644 --- \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" @@ -2,12 +2,14 @@ import os import requests from bs4 import BeautifulSoup from urllib.parse import urljoin +import re CV_DICT = {\"[cgv hive_sdk4_unity_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Unity3D\", \"[cgv hive_sdk4_android_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Android\", \"[cgv hive_sdk4_ios_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/iOS\", \"[cgv hive_sdk4_cpp_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/CPP\", } +WEB_DEV_DOC_BASE = \"https://developers.withhive.com\" def find_html_files(directory): \"\"\"Recursively find all HTML files in the given directory.\"\"\" @@ -33,7 +35,7 @@ def get_hyperlinks(html_file): links = [custom_variable_parser(link) for link in links] return links -def check_link_status(url): +def check_web_link_status(url): \"\"\"Check the status of a hyperlink.\"\"\" try: response = requests.head(url, allow_redirects=True, timeout=5) @@ -44,21 +46,113 @@ def check_link_status(url): except requests.RequestException: return 'Broken' +def check_within_page_link(html_file, relative_link): + with open(html_file, 'r', encoding='utf-8') as file: + contents = file.read() + anchor_pattern = rf'id=(\\\"|\\'){relative_link[1:]}(\\\"|\\')' + match = re.search(anchor_pattern, contents) + if match: + return 'Working' + else: + return 'Broken' + +def check_local_link_status(html_file, relative_link): + \"\"\"Check the status of a local hyperlink.\"\"\" + # \uc6f9 \uc0c1\ub300 \uacbd\ub85c\ub97c \ub85c\uceec \uc0c1\ub300 \uacbd\ub85c\ub85c \ubcf5\uad6c, \uc798\ubabb\ub41c \ud328\ud134 \uc2a4\ud06c\ub9ac\ub2dd \ub4f1 \uc804\ucc98\ub9ac + relative_link_orig = pre_process(relative_link) + if \"#\" in relative_link_orig: + relative_link_orig, id = relative_link_orig.split(\"#\") + else: + id = None + + # relative_link (relative_link_orig) \uc2e4\uc81c\uac12\uc740 2\uac00\uc9c0 \uacbd\uc6b0\uac00 \uc874\uc7ac\ud568. + # 1. \uc6f9 URL \uc0c1\uc758 \uacbd\ub85c(\ud3f4\ub354) + # 2. \uc6f9 URL \uc0c1\uc758 \ub370\uc774\ud130 (\ud398\uc774\uc9c0 \ub610\ub294 HTML \ud30c\uc77c) + # \ud558\uc9c0\ub9cc, relative_link \uac12\uc73c\ub85c \uc774\ub97c \uad6c\ubd84\ud560 \uc218 \uc5c6\uc74c. \ub530\ub77c\uc11c \uc77c\ub2e8 \ubaa8\ub4e0 relative_link\ub294 HTML \ud30c\uc77c\ub85c \uac00\uc815\ud558\uace0, .html \ud655\uc7a5\uc790\ub97c \ubd99\uc5ec\uc90c. \uacbd\ub85c\uac00 \uc874\uc7ac\ud558\ub354\ub77c\ub3c4 \ud30c\uc77c\uc774 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc73c\uba74 Broken\uc73c\ub85c \ucc98\ub9ac\ud568. + # \ub2e8, relative_link \ub9c8\uc9c0\ub9c9\uc5d0 \"/\"\uc774 \uc788\uc73c\uba74, \uc774\ub294 \uacbd\ub85c\ub85c \ucc98\ub9ac\ud560 \uc218 \uc788\uc74c. \uc774 \uacbd\uc6b0\uc5d0\ub294 .html \ud655\uc7a5\uc790\ub97c \ubd99\uc774\uc9c0 \uc54a\uc74c. + # \uc774\ub97c \ub354 \ub0ab\uac8c \uad6c\ud604\ud558\ub824\uba74 Link\ub77c\ub294 \ud074\ub798\uc2a4\ub97c \ub9cc\ub4e4\uace0 \uacbd\ub85c or \ud30c\uc77c \uc5ec\ubd80\ub97c Property\ub85c \ucc98\ub9ac\ud574\uc57c\ud560 \uac83\uc73c\ub85c \ubcf4\uc784. + + # relative_link_orig \ub4a4\uc5d0 /\uac00 \ubd99\uc5b4\uc788\uc73c\uba74 \uacbd\ub85c\ub85c \ucde8\uae09\ud568. \uacbd\ub85c\uc778 \uacbd\uc6b0\uc5d0\ub294 .html \ud655\uc7a5\uc790\ub97c \ubd99\uc774\uc9c0 \uc54a\uc74c. + if relative_link_orig.endswith('/'): + # \uc608\uc678 \ucc98\ub9ac: relative_link_orig\uac00 \uacbd\ub85c\uc778\ub370 id\uac00 \uc788\uc744 \uc218\ub294 \uc5c6\uc73c\ubbc0\ub85c, \uc774\ub7f0 \uacbd\uc6b0\ub294 \ubc14\ub85c Broken \ucc98\ub9ac + if id is not None: + return 'Broken' + + # Convert backslashes to forward slashes for URL formatting + html_file = html_file.replace('\\\\', '/') + # Join the directory (as a URL) with the relative link + resolved_path = urljoin(f'file://{html_file}', relative_link_orig) + local_path = resolved_path.replace('file://', '') + + # relative_link_orig \ub4a4\uc5d0 /\uac00 \uc5c6\uc73c\ubbc0\ub85c \ud30c\uc77c\ub85c \ucde8\uae09\ud574 .html \ud655\uc7a5\uc790\ub97c \ubd99\uc784. + # \ub2e8, /\uac00 \uc5c6\uc5b4\ub3c4 \uacbd\ub85c\uc77c \uc218 \uc788\uc74c. \uc774 \uacbd\uc6b0\ub294 \uacb0\uad6d \uacbd\ub85c.html\uc774 \ub418\uc5b4 Broken\uc73c\ub85c \ucc98\ub9ac\ub418\ubbc0\ub85c safe\ud558\ub2e4\uace0 \ud560 \uc218 \uc788\uc74c. + else: + # Convert backslashes to forward slashes for URL formatting + html_file = html_file.replace('\\\\', '/') + # Join the directory (as a URL) with the relative link + resolved_path = urljoin(f'file://{html_file}', relative_link_orig) + local_path = resolved_path.replace('file://', '') + if local_path.endswith('.html'): + pass + else: + local_path += \".html\" + + # \ud30c\uc77c \ub610\ub294 \uacbd\ub85c\uac00 \uc874\uc7ac\ud558\ub294\uc9c0 \uccb4\ud06c + if os.path.exists(local_path): + if id is None: + return 'Working' + else: + with open(local_path, 'r', encoding='utf-8') as file: + contents = file.read() + anchor_pattern = rf'id=(\\\"|\\'){id}(\\\"|\\')' + match = re.search(anchor_pattern, contents) + if match: + return 'Working' + else: + return 'Broken' + else: + return 'Broken' + +def pre_process(relative_link): + # \uc6cc\ub4dc\ud504\ub808\uc2a4\uc5d0\uc11c \uc4f0\ub294 \uc0c1\ub300\uacbd\ub85c (\uc0c1\uc704 path\ub85c 1\ub2e8\uacc4 \uc62c\ub9bc)\ub97c \uc6d0\ub798 \uc0c1\ub300\uacbd\ub85c\ub85c \ubc14\uafd4\uc90c + # 1\ub2e8\uacc4\uc529 \"\uc81c\uac70\"\ud568. + if relative_link.startswith(\"../../\"): + return relative_link.replace(\"../../\", \"../\") + elif relative_link.startswith(\"../\"): + return relative_link.replace(\"../\", \"./\") + elif relative_link.startswith(\"./\"): + return relative_link.replace(\"./\", \"\") + else: + raise ValueError(\"Invalid relative link: \" + relative_link + \"\") + def check_hyperlinks_in_directory(directory): \"\"\"Check all hyperlinks in all HTML files within a directory.\"\"\" html_files = find_html_files(directory) report = {} for html_file in html_files: - base_url = 'file://' + html_file + # base_url = 'file://' + html_file hyperlinks = get_hyperlinks(html_file) report[html_file] = [] for link in hyperlinks: - # Resolve relative URLs - full_url = urljoin(base_url, link) - status = check_link_status(full_url) - report[html_file].append((link, status)) + # \uc6f9 \ub9c1\ud06c \uccb4\ud06c + if link.startswith(\"http\"): + status = check_web_link_status(link) + report[html_file].append((link, status)) + elif link.startswith('/?page_id='): + link = WEB_DEV_DOC_BASE + link + status = check_web_link_status(link) + report[html_file].append((link, status)) + # \ub85c\uceec \ub9c1\ud06c \uccb4\ud06c + elif link.startswith('./') or link.startswith('../'): + status = check_local_link_status(html_file, link) + report[html_file].append((link, status)) + elif link.startswith('#'): + status = check_within_page_link(html_file, link) + report[html_file].append((link, status)) + else: + raise ValueError(\"Invalid link: \" + link + \"\") return report Commit: 51fb7fa30d43d918e50311d3b0ecb1b53ea290d6 Author : raykim Date : 2024-01-13 20:14:23+09:00 Message : \ub9c1\ud06c \uccb4\ucee4: \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654\ud55c \ub2e4\uc74c \ucf54\ub4dc \ub2e4\uc2dc \uc694\uccad\ud568. \uadfc\ub370 \uc791\ub3d9 \uc548 \ud558\ub294 \ucf54\ub4dc\uc774\uae34 \ub9c8\ucc2c\uac00\uc9c0\uc784. Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker_with_pt_opt.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker_with_pt_opt.py\" new file mode 100644 index 0000000..75b9fbd --- /dev/null +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker_with_pt_opt.py\" @@ -0,0 +1,98 @@ +import os +import requests +from bs4 import BeautifulSoup +from urllib.parse import urljoin, urlparse + +CV_DICT = {\"[cgv hive_sdk4_unity_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Unity3D\", + \"[cgv hive_sdk4_android_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Android\", + \"[cgv hive_sdk4_ios_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/iOS\", + \"[cgv hive_sdk4_cpp_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/CPP\", +} +WEB_DEV_DOC_BASE = \"https://developers.withhive.com\" + +def custom_variable_parser(link, replacements=CV_DICT): + for target, replacement in replacements.items(): + if target in link: + link = link.replace(target, replacement) + return link + +def perm_link_parser(link): + if link.startswith('/?page_id='): + link = WEB_DEV_DOC_BASE + link + return link + +def pre_process(relative_link): + # \uc6cc\ub4dc\ud504\ub808\uc2a4\uc5d0\uc11c \uc4f0\ub294 \uc0c1\ub300\uacbd\ub85c (\uc0c1\uc704 path\ub85c 1\ub2e8\uacc4 \uc62c\ub9bc)\ub97c \uc6d0\ub798 \uc0c1\ub300\uacbd\ub85c\ub85c \ubc14\uafd4\uc90c + # 1\ub2e8\uacc4\uc529 \"\uc81c\uac70\"\ud568. + if relative_link.startswith(\"../../\"): + return relative_link.replace(\"../../\", \"../\") + elif relative_link.startswith(\"../\"): + return relative_link.replace(\"../\", \"./\") + elif relative_link.startswith(\"./\"): + return relative_link.replace(\"./\", \"\") + else: + raise ValueError(\"Invalid relative link: \" + relative_link + \"\") + +def is_valid_url(url): + parsed = urlparse(url) + return bool(parsed.netloc) and bool(parsed.scheme) + +def get_all_html_files(dir): + html_files = [] + for root, dirs, files in os.walk(dir): + for file in files: + if file.endswith('.html'): + html_files.append(os.path.join(root, file)) + return html_files + +def check_link(url, root): + if is_valid_url(url): + try: + response = requests.head(url, allow_redirects=True) + return response.status_code == 200 + except requests.ConnectionError: + return False + else: + return os.path.exists(os.path.join(root, url)) + +def find_and_check_links(file): + with open(file, 'r', encoding='utf-8') as html_file: + soup = BeautifulSoup(html_file, 'html.parser') + links = soup.find_all('a', href=True) + root = os.path.dirname(file) + results = {} + + for link in links: + url = link['href'] + if url.endswith(('.png', '.jpg', '.jpeg', '.gif')): # Skipping image files + continue + if url.startswith('.'): + print(f\"Relative link found: {url}\") + url = pre_process(url) + else: + url = custom_variable_parser(url) + url = perm_link_parser(url) + # \uc774 \ubd80\ubd84 \ucf54\ub4dc\uc5d0 \ubb38\uc81c\uc788\uc74c. + full_url = urljoin('file:', os.path.abspath(url)) + link_status = check_link(full_url, root) + results[full_url] = link_status + return results + +def main(directory): + html_files = get_all_html_files(directory) + all_results = {} + + for file in html_files: + all_results[file] = find_and_check_links(file) + + # Reporting the results + for file, results in all_results.items(): + print(f\"Results for {file}:\") + for link, status in results.items(): + status_text = 'Working' if status else 'Broken or Incorrect' + print(f\" - {link}: {status_text}\") + +if __name__ == \"__main__\": + # directory = input(\"Enter the directory path: \") + directory = 'C:/Users/khy/Documents/personal/workspace/toolbox/\ub9c1\ud06c \uccb4\ucee4/input/dev4/authv4' + main(directory)","title":"Change History"},{"location":"output/#change-history","text":"","title":"Change History"},{"location":"output/#commit-cdfbba1afd7a0c9e9d065ab292f2ddea3de7bb23","text":"Author : raykim Date : 2024-01-13 10:55:58+09:00 Message : \uacbd\ub85c \uc778\uc2dd \ubb38\uc81c. \uc0c1\ub300 \uacbd\ub85c -> \uc808\ub300 \uacbd\ub85c Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" index 707fcfd..414a673 100644 --- \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" @@ -50,7 +50,7 @@ def check_hyperlinks_in_directory(directory): return report # Replace 'your_directory_path' with the path to the directory you want to check -directory_path = './input/dev4' +directory_path = 'C:/Users/khy/Documents/personal/workspace/toolbox/\ub9c1\ud06c \uccb4\ucee4/input/dev4/authv4' link_report = check_hyperlinks_in_directory(directory_path) # Print the report","title":"Commit: cdfbba1afd7a0c9e9d065ab292f2ddea3de7bb23"},{"location":"output/#commit-728f4fa5ab8e981cd7db66bb2cf65db2bea386a1","text":"Author : raykim Date : 2024-01-13 11:33:06+09:00 Message : \ub9c1\ud06c \uc8fc\uc18c \ub0b4\uc5d0 \uc6cc\ub4dc\ud504\ub808\uc2a4 custom variable\uc744 \uc0ac\uc6a9\ud558\ub294 \ub9c1\ud06c\uac00 \uc788\uc74c. \uc774\ub97c \ub2e4\uc2dc \uc815\uc0c1\uc801\uc778 URL \uc8fc\uc18c\ub85c \ubcc0\ud658\ud558\ub294 \uc791\uc5c5 \uad6c\ud604 Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" index 414a673..6ae435c 100644 --- \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" @@ -3,6 +3,12 @@ import requests from bs4 import BeautifulSoup from urllib.parse import urljoin +CV_DICT = {\"[cgv hive_sdk4_unity_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Unity3D\", + \"[cgv hive_sdk4_android_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Android\", + \"[cgv hive_sdk4_ios_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/iOS\", + \"[cgv hive_sdk4_cpp_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/CPP\", +} + def find_html_files(directory): \"\"\"Recursively find all HTML files in the given directory.\"\"\" html_files = [] @@ -12,12 +18,19 @@ def find_html_files(directory): html_files.append(os.path.join(root, file)) return html_files +def custom_variable_parser(link, replacements=CV_DICT): + for target, replacement in replacements.items(): + if target in link: + link = link.replace(target, replacement) + return link + def get_hyperlinks(html_file): \"\"\"Extract hyperlinks from an HTML file, excluding image links.\"\"\" with open(html_file, 'r', encoding='utf-8') as file: contents = file.read() soup = BeautifulSoup(contents, 'html.parser') links = [a['href'] for a in soup.find_all('a', href=True) if not a['href'].lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))] + links = [custom_variable_parser(link) for link in links] return links def check_link_status(url):","title":"Commit: 728f4fa5ab8e981cd7db66bb2cf65db2bea386a1"},{"location":"output/#commit-c4a9daedabf54d07f5086d9be64c090b380dc652","text":"Author : raykim Date : 2024-01-13 16:03:39+09:00 Message : \ub9c1\ud06c \uccb4\ud06c\ub97c, \uc6f9 \ub9c1\ud06c, \ub85c\uceec \ub9c1\ud06c (\ub85c\uceec \ub514\ub809\ud1a0\ub9ac\uc5d0 \uc788\ub294 \ub2e4\ub978 \ud398\uc774\uc9c0\uc758 \ub2e4\ub978 \uc139\uc158\uc5d0 \uc788\ub294 \uc575\ucee4\ub85c \uc774\ub3d9), with-in page \ub85c\uceec \ub9c1\ud06c (\ud604\uc7ac \ud398\uc774\uc9c0\uc758 \ub124\uc784\ub4dc \uc575\ucee4\ub85c \uc774\ub3d9)\ub85c \ub098\ub204\uc5b4\uc11c \uc2e4\ud589. \uc804\ucc98\ub9ac \ud568\uc218\ub294 \uc6f9\uc5d0\uc11c \uc4f0\ub294 \uc0c1\ub300 \uacbd\ub85c\ub97c \ub85c\uceec \uae30\uc900\uc73c\ub85c \ub2e4\uc2dc \ubcc0\ub3d9(1\ub381\uc2a4\uc529 \uc81c\uac70)\ud558\ub294 \uc791\uc5c5 \uc218\ud589. \uc218\uc815\ud55c \uc0c1\ub300 \uacbd\ub85c \ucc98\ub9ac\ub97c \uc544\uc9c1 \ubcf4\uc644\ud574\uc57c \ud568. \ubd88 \ud544\uc694\ud55c \ub85c\uc9c1\uc774 \ub4e4\uc5b4\uac04 \uac83\uc73c\ub85c \ubcf4\uc784. \ub4a4\uc5d0 \"/\"\uac00 \ubd99\uc5c8\uc744 \ub54c \ucc98\ub9ac\uac00 \uacfc\uc5f0 \ud544\uc694\ud55c\uc9c0 \uccb4\ud06c\ud574\uc57c\ud568. Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" index 6ae435c..ea01d58 100644 --- \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker.py\" @@ -2,12 +2,14 @@ import os import requests from bs4 import BeautifulSoup from urllib.parse import urljoin +import re CV_DICT = {\"[cgv hive_sdk4_unity_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Unity3D\", \"[cgv hive_sdk4_android_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Android\", \"[cgv hive_sdk4_ios_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/iOS\", \"[cgv hive_sdk4_cpp_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/CPP\", } +WEB_DEV_DOC_BASE = \"https://developers.withhive.com\" def find_html_files(directory): \"\"\"Recursively find all HTML files in the given directory.\"\"\" @@ -33,7 +35,7 @@ def get_hyperlinks(html_file): links = [custom_variable_parser(link) for link in links] return links -def check_link_status(url): +def check_web_link_status(url): \"\"\"Check the status of a hyperlink.\"\"\" try: response = requests.head(url, allow_redirects=True, timeout=5) @@ -44,21 +46,113 @@ def check_link_status(url): except requests.RequestException: return 'Broken' +def check_within_page_link(html_file, relative_link): + with open(html_file, 'r', encoding='utf-8') as file: + contents = file.read() + anchor_pattern = rf'id=(\\\"|\\'){relative_link[1:]}(\\\"|\\')' + match = re.search(anchor_pattern, contents) + if match: + return 'Working' + else: + return 'Broken' + +def check_local_link_status(html_file, relative_link): + \"\"\"Check the status of a local hyperlink.\"\"\" + # \uc6f9 \uc0c1\ub300 \uacbd\ub85c\ub97c \ub85c\uceec \uc0c1\ub300 \uacbd\ub85c\ub85c \ubcf5\uad6c, \uc798\ubabb\ub41c \ud328\ud134 \uc2a4\ud06c\ub9ac\ub2dd \ub4f1 \uc804\ucc98\ub9ac + relative_link_orig = pre_process(relative_link) + if \"#\" in relative_link_orig: + relative_link_orig, id = relative_link_orig.split(\"#\") + else: + id = None + + # relative_link (relative_link_orig) \uc2e4\uc81c\uac12\uc740 2\uac00\uc9c0 \uacbd\uc6b0\uac00 \uc874\uc7ac\ud568. + # 1. \uc6f9 URL \uc0c1\uc758 \uacbd\ub85c(\ud3f4\ub354) + # 2. \uc6f9 URL \uc0c1\uc758 \ub370\uc774\ud130 (\ud398\uc774\uc9c0 \ub610\ub294 HTML \ud30c\uc77c) + # \ud558\uc9c0\ub9cc, relative_link \uac12\uc73c\ub85c \uc774\ub97c \uad6c\ubd84\ud560 \uc218 \uc5c6\uc74c. \ub530\ub77c\uc11c \uc77c\ub2e8 \ubaa8\ub4e0 relative_link\ub294 HTML \ud30c\uc77c\ub85c \uac00\uc815\ud558\uace0, .html \ud655\uc7a5\uc790\ub97c \ubd99\uc5ec\uc90c. \uacbd\ub85c\uac00 \uc874\uc7ac\ud558\ub354\ub77c\ub3c4 \ud30c\uc77c\uc774 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc73c\uba74 Broken\uc73c\ub85c \ucc98\ub9ac\ud568. + # \ub2e8, relative_link \ub9c8\uc9c0\ub9c9\uc5d0 \"/\"\uc774 \uc788\uc73c\uba74, \uc774\ub294 \uacbd\ub85c\ub85c \ucc98\ub9ac\ud560 \uc218 \uc788\uc74c. \uc774 \uacbd\uc6b0\uc5d0\ub294 .html \ud655\uc7a5\uc790\ub97c \ubd99\uc774\uc9c0 \uc54a\uc74c. + # \uc774\ub97c \ub354 \ub0ab\uac8c \uad6c\ud604\ud558\ub824\uba74 Link\ub77c\ub294 \ud074\ub798\uc2a4\ub97c \ub9cc\ub4e4\uace0 \uacbd\ub85c or \ud30c\uc77c \uc5ec\ubd80\ub97c Property\ub85c \ucc98\ub9ac\ud574\uc57c\ud560 \uac83\uc73c\ub85c \ubcf4\uc784. + + # relative_link_orig \ub4a4\uc5d0 /\uac00 \ubd99\uc5b4\uc788\uc73c\uba74 \uacbd\ub85c\ub85c \ucde8\uae09\ud568. \uacbd\ub85c\uc778 \uacbd\uc6b0\uc5d0\ub294 .html \ud655\uc7a5\uc790\ub97c \ubd99\uc774\uc9c0 \uc54a\uc74c. + if relative_link_orig.endswith('/'): + # \uc608\uc678 \ucc98\ub9ac: relative_link_orig\uac00 \uacbd\ub85c\uc778\ub370 id\uac00 \uc788\uc744 \uc218\ub294 \uc5c6\uc73c\ubbc0\ub85c, \uc774\ub7f0 \uacbd\uc6b0\ub294 \ubc14\ub85c Broken \ucc98\ub9ac + if id is not None: + return 'Broken' + + # Convert backslashes to forward slashes for URL formatting + html_file = html_file.replace('\\\\', '/') + # Join the directory (as a URL) with the relative link + resolved_path = urljoin(f'file://{html_file}', relative_link_orig) + local_path = resolved_path.replace('file://', '') + + # relative_link_orig \ub4a4\uc5d0 /\uac00 \uc5c6\uc73c\ubbc0\ub85c \ud30c\uc77c\ub85c \ucde8\uae09\ud574 .html \ud655\uc7a5\uc790\ub97c \ubd99\uc784. + # \ub2e8, /\uac00 \uc5c6\uc5b4\ub3c4 \uacbd\ub85c\uc77c \uc218 \uc788\uc74c. \uc774 \uacbd\uc6b0\ub294 \uacb0\uad6d \uacbd\ub85c.html\uc774 \ub418\uc5b4 Broken\uc73c\ub85c \ucc98\ub9ac\ub418\ubbc0\ub85c safe\ud558\ub2e4\uace0 \ud560 \uc218 \uc788\uc74c. + else: + # Convert backslashes to forward slashes for URL formatting + html_file = html_file.replace('\\\\', '/') + # Join the directory (as a URL) with the relative link + resolved_path = urljoin(f'file://{html_file}', relative_link_orig) + local_path = resolved_path.replace('file://', '') + if local_path.endswith('.html'): + pass + else: + local_path += \".html\" + + # \ud30c\uc77c \ub610\ub294 \uacbd\ub85c\uac00 \uc874\uc7ac\ud558\ub294\uc9c0 \uccb4\ud06c + if os.path.exists(local_path): + if id is None: + return 'Working' + else: + with open(local_path, 'r', encoding='utf-8') as file: + contents = file.read() + anchor_pattern = rf'id=(\\\"|\\'){id}(\\\"|\\')' + match = re.search(anchor_pattern, contents) + if match: + return 'Working' + else: + return 'Broken' + else: + return 'Broken' + +def pre_process(relative_link): + # \uc6cc\ub4dc\ud504\ub808\uc2a4\uc5d0\uc11c \uc4f0\ub294 \uc0c1\ub300\uacbd\ub85c (\uc0c1\uc704 path\ub85c 1\ub2e8\uacc4 \uc62c\ub9bc)\ub97c \uc6d0\ub798 \uc0c1\ub300\uacbd\ub85c\ub85c \ubc14\uafd4\uc90c + # 1\ub2e8\uacc4\uc529 \"\uc81c\uac70\"\ud568. + if relative_link.startswith(\"../../\"): + return relative_link.replace(\"../../\", \"../\") + elif relative_link.startswith(\"../\"): + return relative_link.replace(\"../\", \"./\") + elif relative_link.startswith(\"./\"): + return relative_link.replace(\"./\", \"\") + else: + raise ValueError(\"Invalid relative link: \" + relative_link + \"\") + def check_hyperlinks_in_directory(directory): \"\"\"Check all hyperlinks in all HTML files within a directory.\"\"\" html_files = find_html_files(directory) report = {} for html_file in html_files: - base_url = 'file://' + html_file + # base_url = 'file://' + html_file hyperlinks = get_hyperlinks(html_file) report[html_file] = [] for link in hyperlinks: - # Resolve relative URLs - full_url = urljoin(base_url, link) - status = check_link_status(full_url) - report[html_file].append((link, status)) + # \uc6f9 \ub9c1\ud06c \uccb4\ud06c + if link.startswith(\"http\"): + status = check_web_link_status(link) + report[html_file].append((link, status)) + elif link.startswith('/?page_id='): + link = WEB_DEV_DOC_BASE + link + status = check_web_link_status(link) + report[html_file].append((link, status)) + # \ub85c\uceec \ub9c1\ud06c \uccb4\ud06c + elif link.startswith('./') or link.startswith('../'): + status = check_local_link_status(html_file, link) + report[html_file].append((link, status)) + elif link.startswith('#'): + status = check_within_page_link(html_file, link) + report[html_file].append((link, status)) + else: + raise ValueError(\"Invalid link: \" + link + \"\") return report","title":"Commit: c4a9daedabf54d07f5086d9be64c090b380dc652"},{"location":"output/#commit-51fb7fa30d43d918e50311d3b0ecb1b53ea290d6","text":"Author : raykim Date : 2024-01-13 20:14:23+09:00 Message : \ub9c1\ud06c \uccb4\ucee4: \ud504\ub86c\ud504\ud2b8 \ucd5c\uc801\ud654\ud55c \ub2e4\uc74c \ucf54\ub4dc \ub2e4\uc2dc \uc694\uccad\ud568. \uadfc\ub370 \uc791\ub3d9 \uc548 \ud558\ub294 \ucf54\ub4dc\uc774\uae34 \ub9c8\ucc2c\uac00\uc9c0\uc784. Changes : diff --git \"a/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker_with_pt_opt.py\" \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker_with_pt_opt.py\" new file mode 100644 index 0000000..75b9fbd --- /dev/null +++ \"b/workspace/toolbox/\\353\\247\\201\\355\\201\\254 \\354\\262\\264\\354\\273\\244/link_checker_with_pt_opt.py\" @@ -0,0 +1,98 @@ +import os +import requests +from bs4 import BeautifulSoup +from urllib.parse import urljoin, urlparse + +CV_DICT = {\"[cgv hive_sdk4_unity_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Unity3D\", + \"[cgv hive_sdk4_android_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/Android\", + \"[cgv hive_sdk4_ios_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/iOS\", + \"[cgv hive_sdk4_cpp_api_ref]\":\"https://developers.withhive.com/HTML/v4_api_reference/CPP\", +} +WEB_DEV_DOC_BASE = \"https://developers.withhive.com\" + +def custom_variable_parser(link, replacements=CV_DICT): + for target, replacement in replacements.items(): + if target in link: + link = link.replace(target, replacement) + return link + +def perm_link_parser(link): + if link.startswith('/?page_id='): + link = WEB_DEV_DOC_BASE + link + return link + +def pre_process(relative_link): + # \uc6cc\ub4dc\ud504\ub808\uc2a4\uc5d0\uc11c \uc4f0\ub294 \uc0c1\ub300\uacbd\ub85c (\uc0c1\uc704 path\ub85c 1\ub2e8\uacc4 \uc62c\ub9bc)\ub97c \uc6d0\ub798 \uc0c1\ub300\uacbd\ub85c\ub85c \ubc14\uafd4\uc90c + # 1\ub2e8\uacc4\uc529 \"\uc81c\uac70\"\ud568. + if relative_link.startswith(\"../../\"): + return relative_link.replace(\"../../\", \"../\") + elif relative_link.startswith(\"../\"): + return relative_link.replace(\"../\", \"./\") + elif relative_link.startswith(\"./\"): + return relative_link.replace(\"./\", \"\") + else: + raise ValueError(\"Invalid relative link: \" + relative_link + \"\") + +def is_valid_url(url): + parsed = urlparse(url) + return bool(parsed.netloc) and bool(parsed.scheme) + +def get_all_html_files(dir): + html_files = [] + for root, dirs, files in os.walk(dir): + for file in files: + if file.endswith('.html'): + html_files.append(os.path.join(root, file)) + return html_files + +def check_link(url, root): + if is_valid_url(url): + try: + response = requests.head(url, allow_redirects=True) + return response.status_code == 200 + except requests.ConnectionError: + return False + else: + return os.path.exists(os.path.join(root, url)) + +def find_and_check_links(file): + with open(file, 'r', encoding='utf-8') as html_file: + soup = BeautifulSoup(html_file, 'html.parser') + links = soup.find_all('a', href=True) + root = os.path.dirname(file) + results = {} + + for link in links: + url = link['href'] + if url.endswith(('.png', '.jpg', '.jpeg', '.gif')): # Skipping image files + continue + if url.startswith('.'): + print(f\"Relative link found: {url}\") + url = pre_process(url) + else: + url = custom_variable_parser(url) + url = perm_link_parser(url) + # \uc774 \ubd80\ubd84 \ucf54\ub4dc\uc5d0 \ubb38\uc81c\uc788\uc74c. + full_url = urljoin('file:', os.path.abspath(url)) + link_status = check_link(full_url, root) + results[full_url] = link_status + return results + +def main(directory): + html_files = get_all_html_files(directory) + all_results = {} + + for file in html_files: + all_results[file] = find_and_check_links(file) + + # Reporting the results + for file, results in all_results.items(): + print(f\"Results for {file}:\") + for link, status in results.items(): + status_text = 'Working' if status else 'Broken or Incorrect' + print(f\" - {link}: {status_text}\") + +if __name__ == \"__main__\": + # directory = input(\"Enter the directory path: \") + directory = 'C:/Users/khy/Documents/personal/workspace/toolbox/\ub9c1\ud06c \uccb4\ucee4/input/dev4/authv4' + main(directory)","title":"Commit: 51fb7fa30d43d918e50311d3b0ecb1b53ea290d6"}]}